{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:04.660515Z",
     "start_time": "2019-05-11T05:30:01.961046Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shijiez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/shijiez/environments/pytorch/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "import time, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import io\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:04.777308Z",
     "start_time": "2019-05-11T05:30:04.663223Z"
    }
   },
   "outputs": [],
   "source": [
    "newsData = pd.read_csv(\"stockNews/Combined_News_DJIA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:04.784504Z",
     "start_time": "2019-05-11T05:30:04.780293Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:04.839751Z",
     "start_time": "2019-05-11T05:30:04.787820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as countries move to brink of war\"</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'</td>\n",
       "      <td>b'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. official says - this is sick, a three year old was raped and they do nothing\"</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO's side\"</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\"</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"'</td>\n",
       "      <td>b'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia's breakaway region of South Ossetia\"</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp;amp; World Report'</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Ossetia'</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"'</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Banned from Olympics'</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?'</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli training, we're fending off Russia \"</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired'</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?'</td>\n",
       "      <td>b'Russia angered by Israeli military sale to Georgia'</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggression?'</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"'</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.'</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Torture'</td>\n",
       "      <td>b' Russia has just beaten the United States over the head with Peak Oil'</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - Russia conflict '</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex for food.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label  \\\n",
       "0  2008-08-08      0   \n",
       "1  2008-08-11      1   \n",
       "\n",
       "                                                                                            Top1  \\\n",
       "0                     b\"Georgia 'downs two Russian warplanes' as countries move to brink of war\"   \n",
       "1  b'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?'   \n",
       "\n",
       "                                          Top2  \\\n",
       "0      b'BREAKING: Musharraf to be impeached.'   \n",
       "1  b'Bush puts foot down on Georgian conflict'   \n",
       "\n",
       "                                                                                          Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'   \n",
       "1           b\"Jewish Georgian minister: Thanks to Israeli training, we're fending off Russia \"   \n",
       "\n",
       "                                                                                                                                          Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'   \n",
       "1                                       b'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired'   \n",
       "\n",
       "                                                                                                                          Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. official says - this is sick, a three year old was raped and they do nothing\"   \n",
       "1                                                                                b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "\n",
       "                                                                                           Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'   \n",
       "1                  b'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?'   \n",
       "\n",
       "                                                                                        Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO's side\"   \n",
       "1                                      b'Russia angered by Israeli military sale to Georgia'   \n",
       "\n",
       "                                                                                                                                                                    Top8  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\"   \n",
       "1                                                        b'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people'   \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "\n",
       "                                                                                                                Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'   \n",
       "1                                                                b'Israel and the US behind the Georgian aggression?'   \n",
       "\n",
       "                                                                               Top17  \\\n",
       "0                                                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"'   \n",
       "\n",
       "                                                                                                                                                                                                         Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"'   \n",
       "1                                                                                                                  b'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.'   \n",
       "\n",
       "                                                                                                                     Top19  \\\n",
       "0  b'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'   \n",
       "1                                                                          b'China to overtake US as largest manufacturer'   \n",
       "\n",
       "                                                                                                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia's breakaway region of South Ossetia\"   \n",
       "1                                                                                                     b'War in South Ossetia [PICS]'   \n",
       "\n",
       "                                                                                  Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report'   \n",
       "1                                    b'Israeli Physicians Group Condemns State Torture'   \n",
       "\n",
       "                                                                      Top22  \\\n",
       "0                      b'Caucasus in crisis: Georgia invades South Ossetia'   \n",
       "1  b' Russia has just beaten the United States over the head with Peak Oil'   \n",
       "\n",
       "                                                                                 Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"'   \n",
       "1                       b'Perhaps *the* question about the Georgia - Russia conflict '   \n",
       "\n",
       "                                                              Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Banned from Olympics'   \n",
       "1                                b'Russia is so much better at war'   \n",
       "\n",
       "                                                    Top25  \n",
       "0                b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex for food.\"  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsTrain = newsData[newsData['Date']< '2015-01-01']\n",
    "newsTest = newsData[newsData['Date']>'2014-12-31']\n",
    "labelTrain = newsTrain['Label'].values\n",
    "labelTest = newsTest['Label'].values\n",
    "newsTrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:04.848396Z",
     "start_time": "2019-05-11T05:30:04.842573Z"
    }
   },
   "outputs": [],
   "source": [
    "def news_to_words( news ):\n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", news) \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 4. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 5. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:06.758291Z",
     "start_time": "2019-05-11T05:30:04.851995Z"
    }
   },
   "outputs": [],
   "source": [
    "trainHeadLines = []\n",
    "for row in range(0,len(newsTrain.index)):\n",
    "#for row in range(0,2):\n",
    "    #pre-process words\n",
    "    combinedNews = \" \".join(str(x).replace(\"b\\\"\",\"\").replace(\"b\\'\",\"\") for x in newsTrain.iloc[row,2:27])\n",
    "    processedNews = news_to_words(combinedNews)\n",
    "    trainHeadLines.append(processedNews)\n",
    "# print(trainheadlines)\n",
    "#print(len(newsTrain.index))\n",
    "\n",
    "testHeadLines = []\n",
    "for row in range(0,len(newsTest.index)):\n",
    "#for row in range(0,2):\n",
    "    #pre-process words\n",
    "    combinedNews = \" \".join(str(x).replace(\"b\\\"\",\"\").replace(\"b\\'\",\"\") for x in newsTest.iloc[row,2:27])\n",
    "    processedNews = news_to_words(combinedNews)\n",
    "    testHeadLines.append(processedNews)\n",
    "# print(trainheadlines)\n",
    "#print(len(newsTrain.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing, split sentences to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:30:06.832586Z",
     "start_time": "2019-05-11T05:30:06.760094Z"
    }
   },
   "outputs": [],
   "source": [
    "tmpHeadLines = []\n",
    "for headLine in trainHeadLines:\n",
    "    headLineSplit = headLine.split(' ')\n",
    "    tmpHeadLines.append(headLineSplit)\n",
    "trainHeadLines = tmpHeadLines\n",
    "\n",
    "tmpHeadLines = []\n",
    "for headLine in testHeadLines:\n",
    "    headLineSplit = headLine.split(' ')\n",
    "    tmpHeadLines.append(headLineSplit)\n",
    "testHeadLines = tmpHeadLines\n",
    "del tmpHeadLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:32:11.985172Z",
     "start_time": "2019-05-11T05:30:06.836227Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shijiez/environments/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/shijiez/word2vec/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "wv = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check vocabulary size\n",
    "over 5000 words not found, initialized to normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:33:22.480149Z",
     "start_time": "2019-05-11T05:32:11.991075Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for line in trainHeadLines:\n",
    "    for word in line:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "\n",
    "for line in testHeadLines:\n",
    "    for word in line:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:33:23.168565Z",
     "start_time": "2019-05-11T05:33:22.481978Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_dim = 300\n",
    "matrix_len = len(vocabulary)\n",
    "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(vocabulary):\n",
    "    try: \n",
    "        weights_matrix[i] = wv[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "\n",
    "weights_matrix = torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to create embedding layer\n",
    "This method by default, assume the embedding layer is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:33:23.318842Z",
     "start_time": "2019-05-11T05:33:23.170376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(33136, 300), 33136, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "create_emb_layer(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:33:23.347080Z",
     "start_time": "2019-05-11T05:33:23.321456Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,   3,  22,  23,  24,  25,  17,\n",
      "         18,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "         39,  40,  41,  42,  43,  34,  44,   3,  22,  45,  17,  18,  46,   0,\n",
      "         47,   2,   3,  48,   9,   0,  49,  17,  18,  12,  50,  51,  52,  53,\n",
      "         54,  55,  56,  44,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
      "         29,  15,  67,  68,  25,  69,  70,  71,  72,  73,  74,  75,  36,  76,\n",
      "          0,   8,  12,  77,  78,  79,  80,  81,  82,  83,  39,  36,  84,  85,\n",
      "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  12,   0,   8,  96,\n",
      "         97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "        111,   5, 112, 113,   8, 114, 115,  13,   0,  49,  17,  18,  12, 116,\n",
      "        117, 118, 119,   0, 120, 121, 122,   8, 123, 124, 125, 126, 127, 128,\n",
      "         77, 129,  51, 130, 131,  85, 132,  83,  85, 133, 134, 135, 136,  81,\n",
      "        137, 138, 139, 140,  86, 141, 142, 143, 144, 145, 146, 147, 148,  83,\n",
      "        149, 150, 151,   0, 152, 153, 154, 155, 156,   3, 157,   0, 158, 159,\n",
      "         17,  18, 160, 161, 162,  83, 163, 164, 129, 165, 166, 113, 167, 168,\n",
      "        169,   0,  49,  17,  18, 170, 171, 172, 173,  66, 174, 175, 176, 177,\n",
      "        178, 179, 101, 155, 180, 181, 182])\n"
     ]
    }
   ],
   "source": [
    "# Turn words list into list of longs\n",
    "def word_tensor(sentenceList):\n",
    "    tensor = torch.zeros(len(sentenceList)).long()\n",
    "    for c in range(len(sentenceList)):\n",
    "        tensor[c] = vocabulary.index(sentenceList[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(word_tensor(trainHeadLines[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to expand label for a sequence, to be equally long, and convert to pytorch format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:33:23.356606Z",
     "start_time": "2019-05-11T05:33:23.350171Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_tensor(label, length):\n",
    "    tensor = torch.ones(length).long()\n",
    "    tensor = tensor * label\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dataset to pytorch format\n",
    "1. convert array of words in the string to array of indecis representing the entry in vector space.\n",
    "2. expand single label to be the same as length array, and convert to pytorch format  \n",
    "Return 2 items, X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:33:23.374543Z",
     "start_time": "2019-05-11T05:33:23.359902Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_pytorch_format(X, y):\n",
    "    M = len(X)\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "\n",
    "    for i in range(M):\n",
    "        sequenceLength = len(X[i])\n",
    "        inp = word_tensor(X[i])\n",
    "        target = label_tensor(y[i], sequenceLength)\n",
    "        X_processed.append(inp)\n",
    "        y_processed.append(target)\n",
    "    return X_processed, y_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:34:32.373015Z",
     "start_time": "2019-05-11T05:33:23.384734Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train) = convert_to_pytorch_format(trainHeadLines, labelTrain)\n",
    "(X_test, y_test) = convert_to_pytorch_format(testHeadLines, labelTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:34:32.388817Z",
     "start_time": "2019-05-11T05:34:32.375009Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    # define model architecture\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        (self.embedding, num_embeddings, embedding_dim) = create_emb_layer(weights_matrix, non_trainable=False)\n",
    "\n",
    "        self.input_size = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # encoder, GRU, decode\n",
    "        # self.embeddings = nn.Embedding.from_pretrained(weights)\n",
    "        # self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.model = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    # forward prop definition  FOR A SINGLE ELEMENT IN THE SEQUENCE\n",
    "    def forward(self, input, hidden):\n",
    "        input = self.embedding(input.view(1, -1))\n",
    "\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.model(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    # Hidden state initialization for a single sequence\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "    \n",
    "    # forward propagate and return last layer softmax output\n",
    "    def output_softmax(self, line_tensor):\n",
    "        hidden = self.init_hidden()\n",
    "        # loop thru sequences, make continuous prediction\n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = self(line_tensor[i], hidden)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    # predict function\n",
    "    def predict_dataset(self, dataset):\n",
    "        predictions = []\n",
    "        for i in range(len(dataset)):\n",
    "            output = self.output_softmax(dataset[i])\n",
    "            predictedLabel = output.argmax()\n",
    "            predictions.append(predictedLabel)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def accuracy(self, dataset, labels):\n",
    "        m = len(labels)\n",
    "        predictions = self.predict_dataset(dataset)\n",
    "        correctCount = np.sum(predictions == labels)\n",
    "        accuracy = correctCount/m\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:34:32.399662Z",
     "start_time": "2019-05-11T05:34:32.392397Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    string_len = len(inp)\n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(string_len):\n",
    "        output, hidden = model(inp[c], hidden)\n",
    "        loss += criterion(output, target[c].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    # print(loss.data)\n",
    "    # print(loss.data.item())\n",
    "    \n",
    "    return loss.data.item() / string_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T05:34:32.412495Z",
     "start_time": "2019-05-11T05:34:32.402882Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T10:40:13.105287Z",
     "start_time": "2019-05-11T06:20:56.626503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  step, accuracy =  0.4947089947089947\n",
      "10  step, accuracy =  0.455026455026455\n",
      "20  step, accuracy =  0.5052910052910053\n",
      "30  step, accuracy =  0.5105820105820106\n",
      "40  step, accuracy =  0.4973544973544973\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "60  step, accuracy =  0.4947089947089947\n",
      "70  step, accuracy =  0.4973544973544973\n",
      "80  step, accuracy =  0.5026455026455027\n",
      "90  step, accuracy =  0.5\n",
      "100  step, accuracy =  0.48677248677248675\n",
      "110  step, accuracy =  0.48412698412698413\n",
      "120  step, accuracy =  0.4894179894179894\n",
      "130  step, accuracy =  0.4947089947089947\n",
      "140  step, accuracy =  0.49206349206349204\n",
      "150  step, accuracy =  0.4894179894179894\n",
      "160  step, accuracy =  0.43386243386243384\n",
      "170  step, accuracy =  0.5026455026455027\n",
      "180  step, accuracy =  0.5079365079365079\n",
      "190  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "210  step, accuracy =  0.5185185185185185\n",
      "220  step, accuracy =  0.5079365079365079\n",
      "230  step, accuracy =  0.5026455026455027\n",
      "240  step, accuracy =  0.5264550264550265\n",
      "250  step, accuracy =  0.5132275132275133\n",
      "260  step, accuracy =  0.48412698412698413\n",
      "270  step, accuracy =  0.5105820105820106\n",
      "280  step, accuracy =  0.5026455026455027\n",
      "290  step, accuracy =  0.5\n",
      "300  step, accuracy =  0.5026455026455027\n",
      "310  step, accuracy =  0.5079365079365079\n",
      "320  step, accuracy =  0.5\n",
      "330  step, accuracy =  0.5079365079365079\n",
      "340  step, accuracy =  0.5079365079365079\n",
      "350  step, accuracy =  0.5105820105820106\n",
      "360  step, accuracy =  0.5105820105820106\n",
      "370  step, accuracy =  0.5105820105820106\n",
      "380  step, accuracy =  0.48677248677248675\n",
      "390  step, accuracy =  0.5\n",
      "400  step, accuracy =  0.5132275132275133\n",
      "410  step, accuracy =  0.5052910052910053\n",
      "420  step, accuracy =  0.5052910052910053\n",
      "430  step, accuracy =  0.5079365079365079\n",
      "440  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.4973544973544973\n",
      "460  step, accuracy =  0.5\n",
      "470  step, accuracy =  0.5026455026455027\n",
      "480  step, accuracy =  0.4656084656084656\n",
      "490  step, accuracy =  0.5079365079365079\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "510  step, accuracy =  0.49206349206349204\n",
      "520  step, accuracy =  0.49206349206349204\n",
      "530  step, accuracy =  0.5026455026455027\n",
      "540  step, accuracy =  0.4947089947089947\n",
      "550  step, accuracy =  0.4973544973544973\n",
      "560  step, accuracy =  0.5079365079365079\n",
      "570  step, accuracy =  0.5079365079365079\n",
      "580  step, accuracy =  0.5052910052910053\n",
      "590  step, accuracy =  0.47883597883597884\n",
      "600  step, accuracy =  0.5026455026455027\n",
      "610  step, accuracy =  0.4947089947089947\n",
      "620  step, accuracy =  0.5\n",
      "630  step, accuracy =  0.5105820105820106\n",
      "640  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5052910052910053\n",
      "660  step, accuracy =  0.5158730158730159\n",
      "670  step, accuracy =  0.5132275132275133\n",
      "680  step, accuracy =  0.5079365079365079\n",
      "690  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "710  step, accuracy =  0.5\n",
      "720  step, accuracy =  0.48677248677248675\n",
      "730  step, accuracy =  0.5079365079365079\n",
      "740  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.48412698412698413\n",
      "760  step, accuracy =  0.5105820105820106\n",
      "770  step, accuracy =  0.47354497354497355\n",
      "780  step, accuracy =  0.5105820105820106\n",
      "790  step, accuracy =  0.5079365079365079\n",
      "800  step, accuracy =  0.5052910052910053\n",
      "810  step, accuracy =  0.5026455026455027\n",
      "820  step, accuracy =  0.5026455026455027\n",
      "830  step, accuracy =  0.5\n",
      "840  step, accuracy =  0.48412698412698413\n",
      "850  step, accuracy =  0.4894179894179894\n",
      "860  step, accuracy =  0.48677248677248675\n",
      "870  step, accuracy =  0.48677248677248675\n",
      "880  step, accuracy =  0.5026455026455027\n",
      "890  step, accuracy =  0.5052910052910053\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "910  step, accuracy =  0.5052910052910053\n",
      "920  step, accuracy =  0.4973544973544973\n",
      "930  step, accuracy =  0.5211640211640212\n",
      "940  step, accuracy =  0.5132275132275133\n",
      "950  step, accuracy =  0.5343915343915344\n",
      "960  step, accuracy =  0.49206349206349204\n",
      "970  step, accuracy =  0.5\n",
      "980  step, accuracy =  0.47354497354497355\n",
      "990  step, accuracy =  0.5158730158730159\n",
      "1000  step, accuracy =  0.4973544973544973\n",
      "1010  step, accuracy =  0.5026455026455027\n",
      "1020  step, accuracy =  0.4947089947089947\n",
      "1030  step, accuracy =  0.5132275132275133\n",
      "1040  step, accuracy =  0.4947089947089947\n",
      "1050  step, accuracy =  0.5\n",
      "1060  step, accuracy =  0.49206349206349204\n",
      "1070  step, accuracy =  0.49206349206349204\n",
      "1080  step, accuracy =  0.4523809523809524\n",
      "1090  step, accuracy =  0.4656084656084656\n",
      "1100  step, accuracy =  0.4947089947089947\n",
      "1110  step, accuracy =  0.47354497354497355\n",
      "1120  step, accuracy =  0.5132275132275133\n",
      "1130  step, accuracy =  0.5105820105820106\n",
      "1140  step, accuracy =  0.5185185185185185\n",
      "1150  step, accuracy =  0.5105820105820106\n",
      "1160  step, accuracy =  0.5132275132275133\n",
      "1170  step, accuracy =  0.5079365079365079\n",
      "1180  step, accuracy =  0.5185185185185185\n",
      "1190  step, accuracy =  0.5079365079365079\n",
      "1200  step, accuracy =  0.5105820105820106\n",
      "1210  step, accuracy =  0.5026455026455027\n",
      "1220  step, accuracy =  0.5052910052910053\n",
      "1230  step, accuracy =  0.4708994708994709\n",
      "1240  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1260  step, accuracy =  0.5634920634920635\n",
      "1270  step, accuracy =  0.4894179894179894\n",
      "1280  step, accuracy =  0.5\n",
      "1290  step, accuracy =  0.5105820105820106\n",
      "1300  step, accuracy =  0.5317460317460317\n",
      "1310  step, accuracy =  0.544973544973545\n",
      "1320  step, accuracy =  0.544973544973545\n",
      "1330  step, accuracy =  0.5026455026455027\n",
      "1340  step, accuracy =  0.5105820105820106\n",
      "1350  step, accuracy =  0.49206349206349204\n",
      "1360  step, accuracy =  0.5079365079365079\n",
      "1370  step, accuracy =  0.5052910052910053\n",
      "1380  step, accuracy =  0.5423280423280423\n",
      "1390  step, accuracy =  0.5079365079365079\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1410  step, accuracy =  0.4947089947089947\n",
      "1420  step, accuracy =  0.49206349206349204\n",
      "1430  step, accuracy =  0.49206349206349204\n",
      "1440  step, accuracy =  0.49206349206349204\n",
      "1450  step, accuracy =  0.48412698412698413\n",
      "1460  step, accuracy =  0.5105820105820106\n",
      "1470  step, accuracy =  0.5105820105820106\n",
      "1480  step, accuracy =  0.5105820105820106\n",
      "1490  step, accuracy =  0.4947089947089947\n",
      "1500  step, accuracy =  0.5052910052910053\n",
      "1510  step, accuracy =  0.5132275132275133\n",
      "1520  step, accuracy =  0.5026455026455027\n",
      "1530  step, accuracy =  0.5\n",
      "1540  step, accuracy =  0.48412698412698413\n",
      "1550  step, accuracy =  0.4947089947089947\n",
      "1560  step, accuracy =  0.4947089947089947\n",
      "1570  step, accuracy =  0.5132275132275133\n",
      "1580  step, accuracy =  0.5105820105820106\n",
      "1590  step, accuracy =  0.5052910052910053\n",
      "1600  step, accuracy =  0.5343915343915344\n",
      "1610  step, accuracy =  0.5317460317460317\n"
     ]
    }
   ],
   "source": [
    "testSampleNo = 0\n",
    "trainSampleNo = 0\n",
    "\n",
    "n_epochs = 1\n",
    "print_every = 100\n",
    "evaluate_every = 10\n",
    "hidden_size = 100\n",
    "vector_size = 300\n",
    "output_size = 2\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "trainM = len(X_train)\n",
    "testM = len(X_test)\n",
    "\n",
    "model = RNN(vector_size, hidden_size, output_size, n_layers)\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for i in range(trainM):\n",
    "        loss = train(X_train[i], y_train[i])\n",
    "        loss_avg += loss\n",
    "        if i % evaluate_every == 0:\n",
    "            print(i , \" step, accuracy = \", model.accuracy(X_test, labelTest))\n",
    "\n",
    "#         if epoch % print_every == 0:\n",
    "#             print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "#             print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "#         if epoch % plot_every == 0:\n",
    "#             all_losses.append(loss_avg / plot_every)\n",
    "#             loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-11T15:09:14.477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  step, accuracy =  0.5370370370370371\n",
      "10  step, accuracy =  0.5132275132275133\n",
      "20  step, accuracy =  0.4947089947089947\n",
      "30  step, accuracy =  0.48148148148148145\n",
      "40  step, accuracy =  0.48148148148148145\n",
      "50  step, accuracy =  0.5052910052910053\n",
      "60  step, accuracy =  0.5423280423280423\n",
      "70  step, accuracy =  0.48677248677248675\n",
      "80  step, accuracy =  0.5264550264550265\n",
      "90  step, accuracy =  0.5661375661375662\n",
      "100  step, accuracy =  0.5052910052910053\n",
      "110  step, accuracy =  0.5026455026455027\n",
      "120  step, accuracy =  0.5264550264550265\n",
      "130  step, accuracy =  0.5158730158730159\n",
      "140  step, accuracy =  0.49206349206349204\n",
      "150  step, accuracy =  0.5158730158730159\n",
      "160  step, accuracy =  0.4708994708994709\n",
      "170  step, accuracy =  0.5052910052910053\n",
      "180  step, accuracy =  0.4947089947089947\n",
      "190  step, accuracy =  0.5211640211640212\n",
      "200  step, accuracy =  0.47619047619047616\n",
      "210  step, accuracy =  0.5079365079365079\n",
      "220  step, accuracy =  0.49206349206349204\n",
      "230  step, accuracy =  0.49206349206349204\n",
      "240  step, accuracy =  0.5079365079365079\n",
      "250  step, accuracy =  0.5\n",
      "260  step, accuracy =  0.5105820105820106\n",
      "270  step, accuracy =  0.4947089947089947\n",
      "280  step, accuracy =  0.4894179894179894\n",
      "290  step, accuracy =  0.49206349206349204\n",
      "300  step, accuracy =  0.5\n",
      "310  step, accuracy =  0.48412698412698413\n",
      "320  step, accuracy =  0.5264550264550265\n",
      "330  step, accuracy =  0.5291005291005291\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    for i in range(trainM):\n",
    "        loss = train(X_train[i], y_train[i])\n",
    "        loss_avg += loss\n",
    "        if i % evaluate_every == 0:\n",
    "            print(i , \" step, accuracy = \", model.accuracy(X_test, labelTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
