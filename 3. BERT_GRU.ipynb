{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wuhn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gensim\n",
    "import time, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import io\n",
    "from torch.autograd import Variable\n",
    "from bert_serving.client import BertClient\n",
    "\n",
    "newsData = pd.read_csv(\"stockNews/Combined_News_DJIA.csv\")\n",
    "pd.set_option('display.max_colwidth', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as countries move to brink of war\"</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'</td>\n",
       "      <td>b'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. official says - this is sick, a three year old was raped and they do nothing\"</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO's side\"</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\"</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"'</td>\n",
       "      <td>b'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia's breakaway region of South Ossetia\"</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp;amp; World Report'</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Ossetia'</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"'</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Banned from Olympics'</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?'</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli training, we're fending off Russia \"</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired'</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?'</td>\n",
       "      <td>b'Russia angered by Israeli military sale to Georgia'</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggression?'</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"'</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.'</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Torture'</td>\n",
       "      <td>b' Russia has just beaten the United States over the head with Peak Oil'</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - Russia conflict '</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex for food.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label  \\\n",
       "0  2008-08-08      0   \n",
       "1  2008-08-11      1   \n",
       "\n",
       "                                                                                            Top1  \\\n",
       "0                     b\"Georgia 'downs two Russian warplanes' as countries move to brink of war\"   \n",
       "1  b'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?'   \n",
       "\n",
       "                                          Top2  \\\n",
       "0      b'BREAKING: Musharraf to be impeached.'   \n",
       "1  b'Bush puts foot down on Georgian conflict'   \n",
       "\n",
       "                                                                                          Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'   \n",
       "1           b\"Jewish Georgian minister: Thanks to Israeli training, we're fending off Russia \"   \n",
       "\n",
       "                                                                                                                                          Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'   \n",
       "1                                       b'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired'   \n",
       "\n",
       "                                                                                                                          Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. official says - this is sick, a three year old was raped and they do nothing\"   \n",
       "1                                                                                b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "\n",
       "                                                                                           Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'   \n",
       "1                  b'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?'   \n",
       "\n",
       "                                                                                        Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO's side\"   \n",
       "1                                      b'Russia angered by Israeli military sale to Georgia'   \n",
       "\n",
       "                                                                                                                                                                    Top8  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\"   \n",
       "1                                                        b'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people'   \n",
       "\n",
       "                            ...                            \\\n",
       "0                           ...                             \n",
       "1                           ...                             \n",
       "\n",
       "                                                                                                                Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'   \n",
       "1                                                                b'Israel and the US behind the Georgian aggression?'   \n",
       "\n",
       "                                                                               Top17  \\\n",
       "0                                                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"'   \n",
       "\n",
       "                                                                                                                                                                                                         Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"'   \n",
       "1                                                                                                                  b'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.'   \n",
       "\n",
       "                                                                                                                     Top19  \\\n",
       "0  b'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'   \n",
       "1                                                                          b'China to overtake US as largest manufacturer'   \n",
       "\n",
       "                                                                                                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia's breakaway region of South Ossetia\"   \n",
       "1                                                                                                     b'War in South Ossetia [PICS]'   \n",
       "\n",
       "                                                                                  Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report'   \n",
       "1                                    b'Israeli Physicians Group Condemns State Torture'   \n",
       "\n",
       "                                                                      Top22  \\\n",
       "0                      b'Caucasus in crisis: Georgia invades South Ossetia'   \n",
       "1  b' Russia has just beaten the United States over the head with Peak Oil'   \n",
       "\n",
       "                                                                                 Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"'   \n",
       "1                       b'Perhaps *the* question about the Georgia - Russia conflict '   \n",
       "\n",
       "                                                              Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Banned from Olympics'   \n",
       "1                                b'Russia is so much better at war'   \n",
       "\n",
       "                                                    Top25  \n",
       "0                b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex for food.\"  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsTrain = newsData[newsData['Date']< '2015-01-01']\n",
    "newsTest = newsData[newsData['Date']>'2014-12-31']\n",
    "labelTrain = newsTrain['Label'].values\n",
    "labelTest = newsTest['Label'].values\n",
    "newsTrain.head(2)\n",
    "#print(newsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_to_words( news ):\n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", news) \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 4. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 5. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Georgia \\'downs two Russian warplanes\\' as countries move to brink of war\"', \"BREAKING: Musharraf to be impeached.'\", \"Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'\", \"Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'\", 'Afghan children raped with \\'impunity,\\' U.N. official says - this is sick, a three year old was raped and they do nothing\"', \"150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'\", 'Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO\\'s side\"', 'The \\'enemy combatent\\' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\"', \"Georgian troops retreat from S. Osettain capital, presumably leaving several hundred people killed. [VIDEO]'\", \"Did the U.S. Prep Georgia for War with Russia?'\", \"Rice Gives Green Light for Israel to Attack Iran: Says U.S. has no veto over Israeli military ops'\", \"Announcing:Class Action Lawsuit on Behalf of American Public Against the FBI'\", 'So---Russia and Georgia are at war and the NYT\\'s top story is opening ceremonies of the Olympics?  What a fucking disgrace and yet further proof of the decline of journalism.\"', 'China tells Bush to stay out of other countries\\' affairs\"', \"Did World War III start today?'\", \"Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'\", \"Al-Qaeda Faces Islamist Backlash'\", 'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"\\'', \"This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'\", 'Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia\\'s breakaway region of South Ossetia\"', \"Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report'\", \"Caucasus in crisis: Georgia invades South Ossetia'\", 'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"\\'', \"Visitors Suffering from Mental Illnesses Banned from Olympics'\", 'No Help for Mexico\\'s Kidnapping Surge\"']\n"
     ]
    }
   ],
   "source": [
    "trainHeadLines = []\n",
    "for row in range(0,len(newsTrain.index)):\n",
    "#for row in range(0,2):\n",
    "    #pre-process words\n",
    "    tempList = []\n",
    "    for col in range(2,27):\n",
    "        combinedNews = \" \".join(str(x).replace(\"b\\\"\",\"\").replace(\"b\\'\",\"\") for x in newsTrain.iloc[row,col:col+1])\n",
    "        #processedNews = news_to_words(combinedNews)\n",
    "        tempList.append(combinedNews)\n",
    "        if '' in tempList:\n",
    "            print(\"empty\",row,col)\n",
    "    trainHeadLines.append(tempList)\n",
    "# print(trainheadlines)\n",
    "#print(len(newsTrain.index))\n",
    "\n",
    "testHeadLines = []\n",
    "for row in range(0,len(newsTest.index)):\n",
    "#for row in range(0,2):\n",
    "    #pre-process words\n",
    "    tempList = []\n",
    "    for col in range(2,27):\n",
    "        combinedNews = \" \".join(str(x).replace(\"b\\\"\",\"\").replace(\"b\\'\",\"\") for x in newsTest.iloc[row,col:col+1])\n",
    "        #processedNews = news_to_words(combinedNews)\n",
    "        tempList.append(combinedNews)\n",
    "        if '' in tempList:\n",
    "            print(\"empty\",row,col)\n",
    "    testHeadLines.append(tempList)\n",
    "#print(len(testHeadLines))\n",
    "print(trainHeadLines[0])\n",
    "#print(len(newsTrain.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn words list into list of longs\n",
    "def word_tensor(sentenceList):\n",
    "    varList = []\n",
    "    bc = BertClient(check_length=False)\n",
    "    #print(len(sentenceList))\n",
    "    for c in range(len(sentenceList)):\n",
    "        tempTensor = torch.from_numpy(bc.encode([sentenceList[c]]))\n",
    "        varList.append(Variable(tempTensor))\n",
    "    return varList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_tensor(label, length):\n",
    "    tensor = torch.ones(length).long()\n",
    "    tensor = tensor * label\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dataset to pytorch format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 0\n",
      "converted 10\n",
      "converted 20\n",
      "converted 30\n",
      "converted 40\n",
      "converted 50\n",
      "converted 60\n",
      "converted 70\n",
      "converted 80\n",
      "converted 90\n",
      "converted 100\n",
      "converted 110\n",
      "converted 120\n",
      "converted 130\n",
      "converted 140\n",
      "converted 150\n",
      "converted 160\n",
      "converted 170\n",
      "converted 180\n",
      "converted 190\n",
      "converted 200\n",
      "converted 210\n",
      "converted 220\n",
      "converted 230\n",
      "converted 240\n",
      "converted 250\n",
      "converted 260\n",
      "converted 270\n",
      "converted 280\n",
      "converted 290\n",
      "converted 300\n",
      "converted 310\n",
      "converted 320\n",
      "converted 330\n",
      "converted 340\n",
      "converted 350\n",
      "converted 360\n",
      "converted 370\n",
      "converted 380\n",
      "converted 390\n",
      "converted 400\n",
      "converted 410\n",
      "converted 420\n",
      "converted 430\n",
      "converted 440\n",
      "converted 450\n",
      "converted 460\n",
      "converted 470\n",
      "converted 480\n",
      "converted 490\n",
      "converted 500\n",
      "converted 510\n",
      "converted 520\n",
      "converted 530\n",
      "converted 540\n",
      "converted 550\n",
      "converted 560\n",
      "converted 570\n",
      "converted 580\n",
      "converted 590\n",
      "converted 600\n",
      "converted 610\n",
      "converted 620\n",
      "converted 630\n",
      "converted 640\n",
      "converted 650\n",
      "converted 660\n",
      "converted 670\n",
      "converted 680\n",
      "converted 690\n",
      "converted 700\n",
      "converted 710\n",
      "converted 720\n",
      "converted 730\n",
      "converted 740\n",
      "converted 750\n",
      "converted 760\n",
      "converted 770\n",
      "converted 780\n",
      "converted 790\n",
      "converted 800\n",
      "converted 810\n",
      "converted 820\n",
      "converted 830\n",
      "converted 840\n",
      "converted 850\n",
      "converted 860\n",
      "converted 870\n",
      "converted 880\n",
      "converted 890\n",
      "converted 900\n",
      "converted 910\n",
      "converted 920\n",
      "converted 930\n",
      "converted 940\n",
      "converted 950\n",
      "converted 960\n",
      "converted 970\n",
      "converted 980\n",
      "converted 990\n",
      "converted 1000\n",
      "converted 1010\n",
      "converted 1020\n",
      "converted 1030\n",
      "converted 1040\n",
      "converted 1050\n",
      "converted 1060\n",
      "converted 1070\n",
      "converted 1080\n",
      "converted 1090\n",
      "converted 1100\n",
      "converted 1110\n",
      "converted 1120\n",
      "converted 1130\n",
      "converted 1140\n",
      "converted 1150\n",
      "converted 1160\n",
      "converted 1170\n",
      "converted 1180\n",
      "converted 1190\n",
      "converted 1200\n",
      "converted 1210\n",
      "converted 1220\n",
      "converted 1230\n",
      "converted 1240\n",
      "converted 1250\n",
      "converted 1260\n",
      "converted 1270\n",
      "converted 1280\n",
      "converted 1290\n",
      "converted 1300\n",
      "converted 1310\n",
      "converted 1320\n",
      "converted 1330\n",
      "converted 1340\n",
      "converted 1350\n",
      "converted 1360\n",
      "converted 1370\n",
      "converted 1380\n",
      "converted 1390\n",
      "converted 1400\n",
      "converted 1410\n",
      "converted 1420\n",
      "converted 1430\n",
      "converted 1440\n",
      "converted 1450\n",
      "converted 1460\n",
      "converted 1470\n",
      "converted 1480\n",
      "converted 1490\n",
      "converted 1500\n",
      "converted 1510\n",
      "converted 1520\n",
      "converted 1530\n",
      "converted 1540\n",
      "converted 1550\n",
      "converted 1560\n",
      "converted 1570\n",
      "converted 1580\n",
      "converted 1590\n",
      "converted 1600\n",
      "converted 1610\n",
      "converted 0\n",
      "converted 10\n",
      "converted 20\n",
      "converted 30\n",
      "converted 40\n",
      "converted 50\n",
      "converted 60\n",
      "converted 70\n",
      "converted 80\n",
      "converted 90\n",
      "converted 100\n",
      "converted 110\n",
      "converted 120\n",
      "converted 130\n",
      "converted 140\n",
      "converted 150\n",
      "converted 160\n",
      "converted 170\n",
      "converted 180\n",
      "converted 190\n",
      "converted 200\n",
      "converted 210\n",
      "converted 220\n",
      "converted 230\n",
      "converted 240\n",
      "converted 250\n",
      "converted 260\n",
      "converted 270\n",
      "converted 280\n",
      "converted 290\n",
      "converted 300\n",
      "converted 310\n",
      "converted 320\n",
      "converted 330\n",
      "converted 340\n",
      "converted 350\n",
      "converted 360\n",
      "converted 370\n"
     ]
    }
   ],
   "source": [
    "def convert_to_pytorch_format(X, y):\n",
    "    M = len(X)\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "\n",
    "    \n",
    "    for i in range(M):\n",
    "        sequenceLength = 768\n",
    "        #print(sequenceLength)\n",
    "        inp = word_tensor(X[i])\n",
    "        target = label_tensor(y[i], sequenceLength)\n",
    "        X_processed.append(inp)\n",
    "        y_processed.append(target)\n",
    "        if i % 10 == 0:\n",
    "            print(\"converted\",i)\n",
    "    return X_processed, y_processed\n",
    "(X_train, y_train) = convert_to_pytorch_format(trainHeadLines, labelTrain)\n",
    "(X_test, y_test) = convert_to_pytorch_format(testHeadLines, labelTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "25\n",
      "40275\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][0].size)\n",
    "print(len(X_train[0]))\n",
    "tempWriteList = []\n",
    "for i in range(len(X_train)):\n",
    "    for j in range(len(X_train[0])):\n",
    "        tempWriteList.append(X_train[i][j])\n",
    "print(len(tempWriteList))\n",
    "for i in range(len(tempWriteList)):\n",
    "    tempWriteList[i] = tempWriteList[i][0]\n",
    "np.savetxt('xtrain.txt',tempWriteList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    for j in range(len(X_train[0])):\n",
    "        X_train[i][j] = torch.from_numpy(X_train[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempWriteList = []\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[0])):\n",
    "        #X_test[i][j] = X_test[i][j].numpy()\n",
    "        tempWriteList.append(X_test[i][j])\n",
    "for i in range(len(tempWriteList)):\n",
    "    tempWriteList[i] = tempWriteList[i][0]\n",
    "np.savetxt('xtest.txt',tempWriteList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[0])):\n",
    "        X_test[i][j] = torch.from_numpy(X_test[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    # define model architecture\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        #(self.embedding, num_embeddings, embedding_dim) = create_emb_layer(weights_matrix, non_trainable=False)\n",
    "        #self.embedding = create_emb_layer()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # encoder, GRU, decode\n",
    "        # self.embeddings = nn.Embedding.from_pretrained(weights)\n",
    "        # self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.model = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    # forward prop definition  FOR A SINGLE ELEMENT IN THE SEQUENCE\n",
    "    def forward(self, input, hidden):\n",
    "        #input = self.embedding(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.model(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    # Hidden state initialization for a single sequence\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "    \n",
    "    # forward propagate and return last layer softmax output\n",
    "    def output_softmax(self, line_tensor):\n",
    "        hidden = self.init_hidden()\n",
    "        # loop thru sequences, make continuous prediction\n",
    "        for i in range(len(line_tensor)):\n",
    "            output, hidden = self(line_tensor[i], hidden)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    # predict function\n",
    "    def predict_dataset(self, dataset):\n",
    "        predictions = []\n",
    "        for i in range(len(dataset)):\n",
    "            output = self.output_softmax(dataset[i])\n",
    "            predictedLabel = output.argmax()\n",
    "            predictions.append(predictedLabel)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def accuracy(self, dataset, labels):\n",
    "        m = len(labels)\n",
    "        predictions = self.predict_dataset(dataset)\n",
    "        correctCount = np.sum(predictions == labels)\n",
    "        accuracy = correctCount/m\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    string_len = len(inp)\n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(string_len):\n",
    "        output, hidden = model(inp[c], hidden)\n",
    "        loss += criterion(output, target[c].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "    \n",
    "    return loss.data.item() / string_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  step, accuracy =  0.49206349206349204\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.49206349206349204\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5079365079365079\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.49206349206349204\n",
      "1350  step, accuracy =  0.49206349206349204\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.49206349206349204\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "1  epoch, accuracy =  0.49206349206349204\n",
      "0  step, accuracy =  0.49206349206349204\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.49206349206349204\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5079365079365079\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.49206349206349204\n",
      "1350  step, accuracy =  0.5079365079365079\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.5079365079365079\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "2  epoch, accuracy =  0.5079365079365079\n",
      "0  step, accuracy =  0.5079365079365079\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5079365079365079\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5079365079365079\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.49206349206349204\n",
      "1350  step, accuracy =  0.5079365079365079\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.5079365079365079\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "3  epoch, accuracy =  0.5079365079365079\n",
      "0  step, accuracy =  0.5079365079365079\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5079365079365079\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5132275132275133\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5079365079365079\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.49206349206349204\n",
      "1350  step, accuracy =  0.49206349206349204\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.49206349206349204\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "4  epoch, accuracy =  0.5079365079365079\n",
      "0  step, accuracy =  0.5079365079365079\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5079365079365079\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5105820105820106\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5105820105820106\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5105820105820106\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.4708994708994709\n",
      "1350  step, accuracy =  0.4656084656084656\n",
      "1400  step, accuracy =  0.5105820105820106\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5052910052910053\n",
      "1550  step, accuracy =  0.49206349206349204\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "5  epoch, accuracy =  0.5105820105820106\n",
      "0  step, accuracy =  0.5052910052910053\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5026455026455027\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5105820105820106\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.4894179894179894\n",
      "1050  step, accuracy =  0.5291005291005291\n",
      "1100  step, accuracy =  0.5079365079365079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150  step, accuracy =  0.5105820105820106\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.49206349206349204\n",
      "1350  step, accuracy =  0.49206349206349204\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.49206349206349204\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "6  epoch, accuracy =  0.5105820105820106\n",
      "0  step, accuracy =  0.5105820105820106\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5185185185185185\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5105820105820106\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5105820105820106\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5079365079365079\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.48677248677248675\n",
      "1350  step, accuracy =  0.48677248677248675\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.4894179894179894\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "7  epoch, accuracy =  0.5079365079365079\n",
      "0  step, accuracy =  0.5079365079365079\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5211640211640212\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.48677248677248675\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.4497354497354497\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5052910052910053\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.5158730158730159\n",
      "1350  step, accuracy =  0.4947089947089947\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.4947089947089947\n",
      "1600  step, accuracy =  0.5079365079365079\n",
      "8  epoch, accuracy =  0.5079365079365079\n",
      "0  step, accuracy =  0.5052910052910053\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.544973544973545\n",
      "150  step, accuracy =  0.4947089947089947\n",
      "200  step, accuracy =  0.4947089947089947\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.47354497354497355\n",
      "350  step, accuracy =  0.5079365079365079\n",
      "400  step, accuracy =  0.5079365079365079\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5079365079365079\n",
      "550  step, accuracy =  0.5079365079365079\n",
      "600  step, accuracy =  0.5079365079365079\n",
      "650  step, accuracy =  0.5079365079365079\n",
      "700  step, accuracy =  0.5079365079365079\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5079365079365079\n",
      "850  step, accuracy =  0.48677248677248675\n",
      "900  step, accuracy =  0.5079365079365079\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5079365079365079\n",
      "1100  step, accuracy =  0.5052910052910053\n",
      "1150  step, accuracy =  0.5052910052910053\n",
      "1200  step, accuracy =  0.5052910052910053\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.5\n",
      "1350  step, accuracy =  0.49206349206349204\n",
      "1400  step, accuracy =  0.5052910052910053\n",
      "1450  step, accuracy =  0.5052910052910053\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.4894179894179894\n",
      "1600  step, accuracy =  0.5052910052910053\n",
      "9  epoch, accuracy =  0.5026455026455027\n",
      "0  step, accuracy =  0.48412698412698413\n",
      "50  step, accuracy =  0.49206349206349204\n",
      "100  step, accuracy =  0.5132275132275133\n",
      "150  step, accuracy =  0.49206349206349204\n",
      "200  step, accuracy =  0.49206349206349204\n",
      "250  step, accuracy =  0.5079365079365079\n",
      "300  step, accuracy =  0.49206349206349204\n",
      "350  step, accuracy =  0.5052910052910053\n",
      "400  step, accuracy =  0.4973544973544973\n",
      "450  step, accuracy =  0.49206349206349204\n",
      "500  step, accuracy =  0.5052910052910053\n",
      "550  step, accuracy =  0.5052910052910053\n",
      "600  step, accuracy =  0.5052910052910053\n",
      "650  step, accuracy =  0.5052910052910053\n",
      "700  step, accuracy =  0.5052910052910053\n",
      "750  step, accuracy =  0.49206349206349204\n",
      "800  step, accuracy =  0.5052910052910053\n",
      "850  step, accuracy =  0.49206349206349204\n",
      "900  step, accuracy =  0.5052910052910053\n",
      "950  step, accuracy =  0.49206349206349204\n",
      "1000  step, accuracy =  0.49206349206349204\n",
      "1050  step, accuracy =  0.5158730158730159\n",
      "1100  step, accuracy =  0.5079365079365079\n",
      "1150  step, accuracy =  0.5\n",
      "1200  step, accuracy =  0.5079365079365079\n",
      "1250  step, accuracy =  0.5079365079365079\n",
      "1300  step, accuracy =  0.47619047619047616\n",
      "1350  step, accuracy =  0.5211640211640212\n",
      "1400  step, accuracy =  0.5079365079365079\n",
      "1450  step, accuracy =  0.5079365079365079\n",
      "1500  step, accuracy =  0.5079365079365079\n",
      "1550  step, accuracy =  0.49206349206349204\n",
      "1600  step, accuracy =  0.5052910052910053\n",
      "10  epoch, accuracy =  0.5026455026455027\n"
     ]
    }
   ],
   "source": [
    "testSampleNo = 0\n",
    "trainSampleNo = 0\n",
    "\n",
    "n_epochs = 100\n",
    "print_every = 100\n",
    "evaluate_every = 50\n",
    "hidden_size = 100\n",
    "vector_size = 768\n",
    "output_size = 2\n",
    "n_layers = 1\n",
    "lr = 0.008\n",
    "trainM = len(X_train)\n",
    "testM = len(X_test)\n",
    "\n",
    "model = RNN(vector_size, hidden_size, output_size, n_layers)\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for i in range(trainM):\n",
    "        loss = train(X_train[i], y_train[i])\n",
    "        loss_avg += loss\n",
    "        if i % evaluate_every == 0:\n",
    "            print(i , \" step, accuracy = \", model.accuracy(X_test, labelTest))\n",
    "    print(epoch , \" epoch, accuracy = \", model.accuracy(X_test, labelTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
